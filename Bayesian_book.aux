\relax 
\@writefile{toc}{\contentsline {chapter}{\numberline {1}How to best use this book}{5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {part}{I\hspace  {1em}Understanding the Bayesian formula}{7}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}The subjective worlds of frequentist and Bayesian statistics}{9}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Likelihoods}{11}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Chapter Mission statement}{11}}
\newlabel{eq:Likelihood_BayesHighlighted}{{3.1}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Chapter goals}{11}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}What is a likelihood?}{12}}
\newlabel{eq:Likelihood_Bayes}{{3.3}{12}}
\newlabel{eq:Likelihood_simple}{{3.3}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Insert bar chart here of the number of heads along the x axis - 0,1,2 - and the associated probability of each of these outcomes as being the bar height - (1/4,1/2,1/4).\relax }}{13}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:Likelihood_fairCoin}{{3.1}{13}}
\newlabel{eq:Likelihood_fairCoin}{{3.3}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces An example posterior distribution for the probability of a heads.\relax }}{14}}
\newlabel{fig:Likelihood_posteriorExample}{{3.2}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces The x-axis here is theta, ranging between 0 and 1, assuming that one head is obtained this graphs the likelihood, which does not sum to 1.\relax }}{14}}
\newlabel{fig:Likelihood_coinLikelihood}{{3.3}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Why is a likelihood not a probability for Bayesians?}{14}}
\newlabel{eq:Likelihood_notation}{{3.4}{15}}
\newlabel{eq:Likelihood_OneHead}{{3.6}{15}}
\newlabel{eq:Likelihood_TwoHead}{{3.8}{15}}
\citation{epstein2008model}
\@writefile{lot}{\contentsline {table}{\numberline {3.1}{\ignorespaces The values of likelihood for the case of tossing a coin twice, where the probability of heads is constrained to take on a discrete value: \{0.0,0.2,0.4,0.6,0.8,1.0\}. In each of the rows, the value of $theta$ is held constant, meaning that $P(data|\theta )$ is a proper probability distribution and thus the probabilities sum to 1. However, in the columns, the data - the number of heads thrown - is held constant, and thus the probabilities do not sum to 1, and we thus we are better off viewing these data as likelihoods, since they do not satisfy the properties of a proper probability distribution.\relax }}{16}}
\newlabel{tab:Likeihood_BayesBox}{{3.1}{16}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}What are models, and why do we need them?}{16}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}How to choose an appropriate model for likelihood?}{18}}
\newlabel{sec:chooseLikelihood}{{3.6}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}A likelihood model for an individual's disease status}{18}}
\newlabel{sec:Likelihood_individualDisease}{{3.6.1}{18}}
\newlabel{eq:Likelihood_SimpleModel1}{{3.10}{19}}
\newlabel{eq:Likelihood_SimpleModel2}{{3.11}{19}}
\newlabel{eq:Likelihood_bernoulli}{{3.6.1}{19}}
\newlabel{eq:Likelihood_SimpleModel3}{{3.13}{19}}
\newlabel{eq:Likelihood_SimpleModel4}{{3.14}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces The likelihood function as theta varies for the case of the two possible data. For a fixed value of $\theta $ we find that the sum across the values of the probability is always 1. This is because when viewed in this way, the likelihood is really a discrete probability density across the two values which x can take on. However, when we hold the data fixed (choose either the red or blue line) and sum the likelihood horizontally across the values of $theta$ we do not find that the sum is generally equal to 1. \relax }}{20}}
\newlabel{fig:Likelihood_bernoulli}{{3.4}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.2}A likelihood model for disease prevalence of a group}{20}}
\newlabel{eq:Likelihood_bernoulli1}{{3.6.2}{22}}
\newlabel{eq:Likelihood_bernoulli2}{{3.16}{22}}
\newlabel{eq:Likelihood_bernoulli3}{{3.17}{22}}
\newlabel{eq:Likelihood_binomialTwo}{{3.6.2}{22}}
\newlabel{eq:Likelihood_binomialTwoProbs}{{3.6.2}{23}}
\newlabel{eq:Likelihood_binomialTwoProbsSimple}{{3.6.2}{23}}
\newlabel{eq:Likelihood_binomialNearly}{{3.6.2}{23}}
\newlabel{eq:Likelihood_quadratic}{{3.6.2}{23}}
\newlabel{eq:Likelihood_nCr}{{3.6.2}{24}}
\newlabel{eq:Likelihood_binomialTwoFull}{{3.6.2}{24}}
\newlabel{eq:Likelihood_binomialThreeProbsSimple}{{3.6.2}{24}}
\newlabel{eq:Likelihood_binomialThreeProbsSimpler}{{3.6.2}{24}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces The likelihood function as theta varies for the case of the two possible data. For a fixed value of $\theta $ we find that the sum across the values of the probability is always 1. This is because when viewed in this way, the likelihood is really a discrete probability density across the two values which x can take on. However, when we hold the data fixed (choose either the red or blue line) and sum area under the likelihood curve across the values of $theta$ we do not find that the sum is generally equal to 1. \relax }}{25}}
\newlabel{fig:Likelihood_binomial}{{3.5}{25}}
\newlabel{eq:Likelihood_binomialThreeFull}{{3.6.2}{26}}
\newlabel{eq:Likelihood_binomialNFull}{{3.6.2}{26}}
\newlabel{eq:Likelihood_binomialTest}{{3.6.2}{26}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.3}The intelligence of a group of people}{27}}
\bibstyle{plain}
\bibdata{Bayes}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.4}Summing up - specifying a likelihood}{28}}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Maximum likelihood - a short introduction}{28}}
\newlabel{sec:Likelihood_MLE}{{3.7}{28}}
\@writefile{toc}{\contentsline {section}{\numberline {3.8}The subjectivity of model choice}{28}}
\@writefile{toc}{\contentsline {section}{\numberline {3.9}Chapter summary}{28}}
\bibcite{epstein2008model}{{1}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
