\contentsline {chapter}{\numberline {1}How to best use this book}{11}
\contentsline {section}{\numberline {1.1}Why don't more people use Bayesian statistics?}{11}
\contentsline {part}{I\hspace {1em}Understanding the Bayesian formula}{13}
\contentsline {chapter}{\numberline {2}The subjective worlds of Frequentist and Bayesian statistics}{15}
\contentsline {section}{\numberline {2.1}Chapter mission statement}{15}
\contentsline {section}{\numberline {2.2}Chapter goals}{15}
\contentsline {section}{\numberline {2.3}The purpose of statistical inference}{16}
\contentsline {section}{\numberline {2.4}The world according to Frequentists}{17}
\contentsline {section}{\numberline {2.5}The world according to Bayesians}{18}
\contentsline {section}{\numberline {2.6}Frequentist and Bayesian inference}{19}
\contentsline {subsection}{\numberline {2.6.1}The Frequentist and Bayesian murder trials}{20}
\contentsline {subsection}{\numberline {2.6.2}Radio control towers: example}{21}
\contentsline {section}{\numberline {2.7}Probability distributions: helping us explicitly state our ignorance}{22}
\contentsline {subsection}{\numberline {2.7.1}What make a probability distribution \textit {valid}?}{23}
\contentsline {subsection}{\numberline {2.7.2}Interpreting discrete and continuous probability distributions}{24}
\contentsline {subsection}{\numberline {2.7.3}Mean and variance of distributions}{26}
\contentsline {subsection}{\numberline {2.7.4}Generalising probability distributions to two dimensions}{31}
\contentsline {subsubsection}{Horses for courses: a 2-dimensional discrete probability example}{31}
\contentsline {subsubsection}{Foot length and intelligence: a 2-dimensional continuous probability example}{32}
\contentsline {subsection}{\numberline {2.7.5}Marginal distributions}{33}
\contentsline {subsection}{\numberline {2.7.6}Conditional distributions}{37}
\contentsline {section}{\numberline {2.8}Higher dimensional probability densities: no harder than 2-D, just looks it!}{41}
\contentsline {section}{\numberline {2.9}Independence}{43}
\contentsline {section}{\numberline {2.10}Central Limit Theorems}{45}
\contentsline {section}{\numberline {2.11}The Bayesian formula}{47}
\contentsline {subsection}{\numberline {2.11.1}The intuition behind the formula}{48}
\contentsline {section}{\numberline {2.12}The Bayesian inference process from the Bayesian formula}{50}
\contentsline {subsection}{\numberline {2.12.1}Likelihoods}{51}
\contentsline {subsection}{\numberline {2.12.2}Priors}{52}
\contentsline {subsection}{\numberline {2.12.3}The denominator}{53}
\contentsline {subsection}{\numberline {2.12.4}Posteriors: the goal of Bayesian inference}{53}
\contentsline {section}{\numberline {2.13}Implicit vs Explicit subjectivity}{55}
\contentsline {section}{\numberline {2.14}What are the tangible (non-academic) benefits of Bayesian statistics?}{56}
\contentsline {section}{\numberline {2.15}Appendix}{57}
\contentsline {subsection}{\numberline {2.15.1}The Frequentist and Bayesian murder trial}{57}
\contentsline {chapter}{\numberline {3}The posterior - the goal of Bayesian inference}{59}
\contentsline {section}{\numberline {3.1}Chapter Mission statement}{59}
\contentsline {section}{\numberline {3.2}Chapter goals}{59}
\contentsline {section}{\numberline {3.3}Expressing uncertainty through the posterior probability distribution}{60}
\contentsline {subsection}{\numberline {3.3.1}Bayesian coastguard: introducing the prior and the posterior}{63}
\contentsline {subsection}{\numberline {3.3.2}Bayesian statistics: updating our pre-analysis uncertainty}{63}
\contentsline {subsection}{\numberline {3.3.3}Do parameters actually exist and have a point value?}{65}
\contentsline {subsection}{\numberline {3.3.4}Failings of the Frequentist confidence interval}{67}
\contentsline {subsection}{\numberline {3.3.5}Credible intervals}{69}
\contentsline {subsubsection}{Treasure hunting: The central posterior and highest density intervals}{70}
\contentsline {subsection}{\numberline {3.3.6}Reconciling the difference between confidence and credible intervals}{71}
\contentsline {subsubsection}{The interval ENIGMA}{72}
\contentsline {section}{\numberline {3.4}Prediction using predictive distributions}{75}
\contentsline {subsection}{\numberline {3.4.1}Example: number of Republican voters within a sample}{75}
\contentsline {subsection}{\numberline {3.4.2}Example: interest rate hedging}{78}
\contentsline {section}{\numberline {3.5}Model comparison using the posterior}{82}
\contentsline {subsection}{\numberline {3.5.1}Example: epidemiologist comparison}{85}
\contentsline {subsection}{\numberline {3.5.2}Example: customer footfall}{86}
\contentsline {section}{\numberline {3.6}Model comparison through posterior predictive checks}{88}
\contentsline {subsection}{\numberline {3.6.1}Example: stock returns}{89}
\contentsline {section}{\numberline {3.7}Chapter summary}{90}
\contentsline {section}{\numberline {3.8}Appendix}{91}
\contentsline {subsection}{\numberline {3.8.1}The interval ENIGMA - explained in full}{91}
\contentsline {chapter}{\numberline {4}Likelihoods}{93}
\contentsline {section}{\numberline {4.1}Chapter Mission statement}{93}
\contentsline {section}{\numberline {4.2}Chapter goals}{93}
\contentsline {section}{\numberline {4.3}What is a likelihood?}{94}
\contentsline {section}{\numberline {4.4}Why use 'likelihood' rather than 'probability'?}{96}
\contentsline {section}{\numberline {4.5}What are models and why do we need them?}{100}
\contentsline {section}{\numberline {4.6}How to choose an appropriate likelihood?}{101}
\contentsline {subsection}{\numberline {4.6.1}A likelihood model for an individual's disease status}{102}
\contentsline {subsection}{\numberline {4.6.2}A likelihood model for disease prevalence of a group}{104}
\contentsline {subsection}{\numberline {4.6.3}The intelligence of a group of people}{109}
\contentsline {section}{\numberline {4.7}Exchangeability vs random sampling}{111}
\contentsline {section}{\numberline {4.8}The subjectivity of model choice}{113}
\contentsline {section}{\numberline {4.9}Maximum likelihood - a short introduction}{114}
\contentsline {subsection}{\numberline {4.9.1}Estimating disease prevalence}{114}
\contentsline {subsection}{\numberline {4.9.2}Estimating the mean and variance in intelligence scores}{117}
\contentsline {section}{\numberline {4.10}Frequentist inference in Maximum Likelihood}{118}
\contentsline {section}{\numberline {4.11}Chapter summary}{120}
\contentsline {chapter}{\numberline {5}Priors}{121}
\contentsline {section}{\numberline {5.1}Chapter Mission statement}{121}
\contentsline {section}{\numberline {5.2}Chapter goals}{121}
\contentsline {section}{\numberline {5.3}What are priors, and what do they represent?}{122}
\contentsline {section}{\numberline {5.4}Why do we need priors at all?}{124}
\contentsline {section}{\numberline {5.5}Why don't we just normalise likelihood by choosing a unity prior?}{125}
\contentsline {section}{\numberline {5.6}The explicit subjectivity of priors}{127}
\contentsline {section}{\numberline {5.7}Interpreting priors through prior predictive distributions}{128}
\contentsline {section}{\numberline {5.8}Combining a prior and likelihood to form a posterior}{128}
\contentsline {subsection}{\numberline {5.8.1}An urn of balls\let \reserved@d =[\def \par }{128}
\contentsline {subsection}{\numberline {5.8.2}Disease proportions revisited}{131}
\contentsline {section}{\numberline {5.9}Constructing priors}{134}
\contentsline {subsection}{\numberline {5.9.1}Vague priors}{134}
\contentsline {subsection}{\numberline {5.9.2}Informative priors}{136}
\contentsline {subsection}{\numberline {5.9.3}The numerator of Bayes' rule determines the shape}{139}
\contentsline {subsection}{\numberline {5.9.4}Eliciting priors}{139}
\contentsline {section}{\numberline {5.10}A strong model is not heavily influenced by priors}{141}
\contentsline {section}{\numberline {5.11}Chapter summary}{143}
\contentsline {section}{\numberline {5.12}Appendix}{143}
\contentsline {subsection}{\numberline {5.12.1}Bayes' rule for the urn}{143}
\contentsline {subsection}{\numberline {5.12.2}The probabilities of having a disease}{144}
\contentsline {chapter}{\numberline {6}The devil's in the denominator}{145}
\contentsline {section}{\numberline {6.1}Chapter mission}{145}
\contentsline {section}{\numberline {6.2}Chapter goals}{145}
\contentsline {section}{\numberline {6.3}An introduction to the denominator}{146}
\contentsline {subsection}{\numberline {6.3.1}The denominator as a normalising factor}{146}
\contentsline {subsection}{\numberline {6.3.2}Example: disease}{147}
\contentsline {subsection}{\numberline {6.3.3}Example: the proportion of people who vote for conservatively}{150}
\contentsline {subsection}{\numberline {6.3.4}The denominator as a probability}{152}
\contentsline {subsection}{\numberline {6.3.5}Using the denominator to choose between competing models}{153}
\contentsline {subsection}{\numberline {6.3.6}The denominator for improper priors}{157}
\contentsline {section}{\numberline {6.4}The difficulty with the denominator}{157}
\contentsline {subsection}{\numberline {6.4.1}Multi-parameter discrete model example: the comorbidity between depression and anxiety}{158}
\contentsline {subsection}{\numberline {6.4.2}Continuous multi-parameter example: mean and variance of IQ}{160}
\contentsline {section}{\numberline {6.5}How to dispense with the difficulty: Bayesian computation}{163}
\contentsline {section}{\numberline {6.6}Chapter summary}{165}
\contentsline {section}{\numberline {6.7}Appendix}{165}
\contentsline {part}{II\hspace {1em}Analytic Bayesian methods}{167}
\contentsline {chapter}{\numberline {7}An introduction to distributions for the mathematically-un-inclined}{169}
\contentsline {section}{\numberline {7.1}Chapter mission statement}{169}
\contentsline {section}{\numberline {7.2}Chapter goals}{169}
\contentsline {section}{\numberline {7.3}Sampling distributions for likelihoods}{169}
\contentsline {subsubsection}{Bernoulli}{169}
\contentsline {subsubsection}{Binomial}{172}
\contentsline {subsubsection}{Normal}{175}
\contentsline {subsubsection}{Poisson}{175}
\contentsline {subsubsection}{Negative binomial}{175}
\contentsline {subsubsection}{Logistic}{175}
\contentsline {section}{\numberline {7.4}Prior distributions}{175}
\contentsline {subsubsection}{Distributions for probabilities, proportions and percentages}{175}
\contentsline {subsubsection}{Uniform}{175}
\contentsline {subsubsection}{Beta}{175}
\contentsline {subsubsection}{Dirichlet}{175}
\contentsline {section}{\numberline {7.5}Table of distributions, their uses, and reasonable priors}{175}
\contentsline {subsection}{\numberline {7.5.1}Distributions for means and medians}{175}
\contentsline {subsubsection}{Normal}{175}
\contentsline {subsubsection}{Student t}{175}
\contentsline {subsection}{\numberline {7.5.2}Distributions for variances, and shape parameters}{175}
\contentsline {subsubsection}{Gamma}{175}
\contentsline {subsubsection}{Half-Cauchy}{175}
\contentsline {subsubsection}{Inverse Gamma}{175}
\contentsline {subsubsection}{Inverse chi}{175}
\contentsline {subsection}{\numberline {7.5.3}Multinomial - or other regression}{175}
\contentsline {subsection}{\numberline {7.5.4}LBG prior - see Michael Betancourt video and Stan doc}{175}
\contentsline {subsection}{\numberline {7.5.5}Wishart}{176}
\contentsline {subsection}{\numberline {7.5.6}Distributions for categories}{176}
\contentsline {subsubsection}{Categorical}{176}
\contentsline {section}{\numberline {7.6}Chapter summary}{176}
\contentsline {chapter}{\numberline {8}Conjugate priors and their place in Bayesian analysis}{177}
\contentsline {chapter}{\numberline {9}Objective Bayesian analysis}{179}
\contentsline {part}{III\hspace {1em}A practical guide to doing real life Bayesian analysis: Computational Bayes}{181}
\contentsline {part}{IV\hspace {1em}Regression analysis and hierarchical models}{183}
\contentsline {chapter}{\numberline {10}Hierarchical models}{185}
\contentsline {chapter}{\numberline {11}Hypothesis testing I: Classical Frequentist vs Bayesian approaches}{187}
\contentsline {chapter}{\numberline {12}Evaluation of model fit}{189}
