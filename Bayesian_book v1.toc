\contentsline {chapter}{\numberline {1}How to best use this book}{11}
\contentsline {section}{\numberline {1.1}The purpose of this book}{11}
\contentsline {section}{\numberline {1.2}Who is this book for?}{13}
\contentsline {section}{\numberline {1.3}Pre-requisites}{13}
\contentsline {section}{\numberline {1.4}Book outline}{14}
\contentsline {section}{\numberline {1.5}Route planner - suggested journeys through Bayesland}{16}
\contentsline {section}{\numberline {1.6}Video}{17}
\contentsline {section}{\numberline {1.7}Interactive elements}{17}
\contentsline {section}{\numberline {1.8}Interactive problem sets}{18}
\contentsline {section}{\numberline {1.9}Code}{18}
\contentsline {section}{\numberline {1.10}R, Stan and JAGS}{18}
\contentsline {section}{\numberline {1.11}Why don't more people use Bayesian statistics?}{19}
\contentsline {section}{\numberline {1.12}What are the tangible (non-academic) benefits of Bayesian statistics?}{20}
\contentsline {section}{\numberline {1.13}Suggested further reading}{21}
\contentsline {part}{I\hspace {1em}An introduction to Bayesian inference}{23}
\contentsline {section}{\numberline {1.14}Part mission statement}{25}
\contentsline {section}{\numberline {1.15}Part goals}{25}
\contentsline {chapter}{\numberline {2}The subjective worlds of Frequentist and Bayesian statistics}{27}
\contentsline {section}{\numberline {2.1}Chapter mission statement}{27}
\contentsline {section}{\numberline {2.2}Chapter goals}{27}
\contentsline {section}{\numberline {2.3}Bayes' rule - allowing us to go from the effect back to its cause}{28}
\contentsline {section}{\numberline {2.4}The purpose of statistical inference}{29}
\contentsline {section}{\numberline {2.5}The world according to Frequentists}{30}
\contentsline {section}{\numberline {2.6}The world according to Bayesians}{32}
\contentsline {section}{\numberline {2.7}Frequentist and Bayesian inference}{33}
\contentsline {subsection}{\numberline {2.7.1}The Frequentist and Bayesian murder trials}{34}
\contentsline {subsection}{\numberline {2.7.2}Radio control towers: example}{35}
\contentsline {section}{\numberline {2.8}Bayesian inference via Bayes' rule}{36}
\contentsline {subsection}{\numberline {2.8.1}Likelihoods}{37}
\contentsline {subsection}{\numberline {2.8.2}Priors}{38}
\contentsline {subsection}{\numberline {2.8.3}The denominator}{39}
\contentsline {subsection}{\numberline {2.8.4}Posteriors: the goal of Bayesian inference}{39}
\contentsline {section}{\numberline {2.9}Implicit vs Explicit subjectivity}{40}
\contentsline {section}{\numberline {2.10}Chapter summary}{42}
\contentsline {section}{\numberline {2.11}Chapter outcomes}{43}
\contentsline {section}{\numberline {2.12}Problem set}{43}
\contentsline {section}{\numberline {2.13}Appendix}{43}
\contentsline {subsection}{\numberline {2.13.1}The Frequentist and Bayesian murder trial}{43}
\contentsline {chapter}{\numberline {3}Probability - the nuts and bolts of Bayesian inference}{45}
\contentsline {section}{\numberline {3.1}Chapter mission statement}{45}
\contentsline {section}{\numberline {3.2}Chapter goals}{45}
\contentsline {section}{\numberline {3.3}Probability distributions: helping us explicitly state our ignorance}{46}
\contentsline {subsection}{\numberline {3.3.1}What make a probability distribution \textit {valid}?}{46}
\contentsline {subsection}{\numberline {3.3.2}Probabilities vs probability density : interpreting discrete and continuous probability distributions}{48}
\contentsline {subsection}{\numberline {3.3.3}Mean and variance of distributions}{49}
\contentsline {subsection}{\numberline {3.3.4}Generalising probability distributions to two dimensions}{54}
\contentsline {subsubsection}{Horses for courses: a 2-dimensional discrete probability example}{55}
\contentsline {subsubsection}{Foot length and intelligence: a 2-dimensional continuous probability example}{56}
\contentsline {subsection}{\numberline {3.3.5}Marginal distributions}{57}
\contentsline {subsubsection}{Venn diagrams}{59}
\contentsline {subsection}{\numberline {3.3.6}Conditional distributions}{61}
\contentsline {section}{\numberline {3.4}Higher dimensional probability densities: no harder than 2-D, just looks it!}{64}
\contentsline {section}{\numberline {3.5}Independence}{66}
\contentsline {section}{\numberline {3.6}Central Limit Theorems}{69}
\contentsline {section}{\numberline {3.7}The Bayesian formula}{71}
\contentsline {subsection}{\numberline {3.7.1}The intuition behind the formula}{72}
\contentsline {section}{\numberline {3.8}The Bayesian inference process from the Bayesian formula}{74}
\contentsline {section}{\numberline {3.9}Chapter summary}{75}
\contentsline {section}{\numberline {3.10}Problem set}{75}
\contentsline {section}{\numberline {3.11}Chapter outcomes}{75}
\contentsline {part}{II\hspace {1em}Understanding the Bayesian formula}{77}
\contentsline {section}{\numberline {3.12}Part mission statement}{79}
\contentsline {section}{\numberline {3.13}Part goals}{79}
\contentsline {chapter}{\numberline {4}The posterior - the goal of Bayesian inference}{81}
\contentsline {section}{\numberline {4.1}Chapter Mission statement}{81}
\contentsline {section}{\numberline {4.2}Chapter goals}{81}
\contentsline {section}{\numberline {4.3}Expressing uncertainty through the posterior probability distribution}{82}
\contentsline {subsection}{\numberline {4.3.1}Bayesian coastguard: introducing the prior and the posterior}{85}
\contentsline {subsection}{\numberline {4.3.2}Bayesian statistics: updating our pre-analysis uncertainty}{85}
\contentsline {subsection}{\numberline {4.3.3}Do parameters actually exist and have a point value?}{87}
\contentsline {subsection}{\numberline {4.3.4}Failings of the Frequentist confidence interval}{89}
\contentsline {subsection}{\numberline {4.3.5}Credible intervals}{91}
\contentsline {subsubsection}{Treasure hunting: The central posterior and highest density intervals}{92}
\contentsline {subsection}{\numberline {4.3.6}Reconciling the difference between confidence and credible intervals}{93}
\contentsline {subsubsection}{The interval ENIGMA}{94}
\contentsline {section}{\numberline {4.4}Prediction using predictive distributions}{97}
\contentsline {subsection}{\numberline {4.4.1}Example: number of Republican voters within a sample}{97}
\contentsline {subsection}{\numberline {4.4.2}Example: interest rate hedging}{100}
\contentsline {section}{\numberline {4.5}Model comparison using the posterior}{104}
\contentsline {subsection}{\numberline {4.5.1}Example: epidemiologist comparison}{107}
\contentsline {subsection}{\numberline {4.5.2}Example: customer footfall}{108}
\contentsline {section}{\numberline {4.6}Model comparison through posterior predictive checks}{110}
\contentsline {subsection}{\numberline {4.6.1}Example: stock returns}{111}
\contentsline {section}{\numberline {4.7}Chapter summary}{112}
\contentsline {section}{\numberline {4.8}Chapter outcomes}{113}
\contentsline {section}{\numberline {4.9}Problem set}{113}
\contentsline {section}{\numberline {4.10}Appendix}{113}
\contentsline {subsection}{\numberline {4.10.1}The interval ENIGMA - explained in full}{113}
\contentsline {chapter}{\numberline {5}Likelihoods}{115}
\contentsline {section}{\numberline {5.1}Chapter Mission statement}{115}
\contentsline {section}{\numberline {5.2}Chapter goals}{115}
\contentsline {section}{\numberline {5.3}What is a likelihood?}{116}
\contentsline {section}{\numberline {5.4}Why use 'likelihood' rather than 'probability'?}{118}
\contentsline {section}{\numberline {5.5}What are models and why do we need them?}{122}
\contentsline {section}{\numberline {5.6}How to choose an appropriate likelihood?}{123}
\contentsline {subsection}{\numberline {5.6.1}A likelihood model for an individual's disease status}{124}
\contentsline {subsection}{\numberline {5.6.2}A likelihood model for disease prevalence of a group}{126}
\contentsline {subsection}{\numberline {5.6.3}The intelligence of a group of people}{131}
\contentsline {section}{\numberline {5.7}Exchangeability vs random sampling}{133}
\contentsline {section}{\numberline {5.8}The subjectivity of model choice}{135}
\contentsline {section}{\numberline {5.9}Maximum likelihood - a short introduction}{136}
\contentsline {subsection}{\numberline {5.9.1}Estimating disease prevalence}{136}
\contentsline {subsection}{\numberline {5.9.2}Estimating the mean and variance in intelligence scores}{139}
\contentsline {section}{\numberline {5.10}Frequentist inference in Maximum Likelihood}{140}
\contentsline {section}{\numberline {5.11}Chapter summary}{142}
\contentsline {section}{\numberline {5.12}Chapter outcomes}{142}
\contentsline {section}{\numberline {5.13}Problem set}{142}
\contentsline {subsection}{\numberline {5.13.1}Blog blues.}{142}
\contentsline {subsubsection}{What assumptions might you make about the first-time visits?}{143}
\contentsline {subsubsection}{What model might be appropriate to model the time between visits?}{143}
\contentsline {subsubsection}{Algebraically derive an estimate of the mean number of visits per hour}{143}
\contentsline {subsubsection}{Data analysis:}{143}
\contentsline {subsubsection}{Derive estimates of the confidence intervals around this parameter.}{143}
\contentsline {subsubsection}{What is the probability that you will wait:}{143}
\contentsline {subsubsection}{Evaluate your model.}{143}
\contentsline {subsubsection}{What alternative models might be useful here?}{143}
\contentsline {subsubsection}{What are the assumptions behind these models?}{143}
\contentsline {subsubsection}{Estimate the parameters of your new model.}{143}
\contentsline {subsubsection}{Use your new model to estimate the probability that you will wait:}{143}
\contentsline {subsubsection}{Hints:}{144}
\contentsline {chapter}{\numberline {6}Priors}{145}
\contentsline {section}{\numberline {6.1}Chapter Mission statement}{145}
\contentsline {section}{\numberline {6.2}Chapter goals}{145}
\contentsline {section}{\numberline {6.3}What are priors, and what do they represent?}{146}
\contentsline {section}{\numberline {6.4}Why do we need priors at all?}{148}
\contentsline {section}{\numberline {6.5}Why don't we just normalise likelihood by choosing a unity prior?}{149}
\contentsline {section}{\numberline {6.6}The explicit subjectivity of priors}{151}
\contentsline {section}{\numberline {6.7}Interpreting priors through prior predictive distributions}{152}
\contentsline {section}{\numberline {6.8}Combining a prior and likelihood to form a posterior}{152}
\contentsline {subsection}{\numberline {6.8.1}The Goldfish game}{152}
\contentsline {subsection}{\numberline {6.8.2}Disease proportions revisited}{155}
\contentsline {subsubsection}{Interactive effect of the prior on the posterior}{157}
\contentsline {section}{\numberline {6.9}Constructing priors}{157}
\contentsline {subsection}{\numberline {6.9.1}Vague priors}{157}
\contentsline {subsection}{\numberline {6.9.2}Informative priors}{161}
\contentsline {subsection}{\numberline {6.9.3}The numerator of Bayes' rule determines the shape}{164}
\contentsline {subsection}{\numberline {6.9.4}Eliciting priors}{164}
\contentsline {section}{\numberline {6.10}A strong model is not heavily influenced by priors}{166}
\contentsline {section}{\numberline {6.11}Chapter summary}{168}
\contentsline {section}{\numberline {6.12}Chapter outcomes}{168}
\contentsline {section}{\numberline {6.13}Problem set}{168}
\contentsline {section}{\numberline {6.14}Appendix}{168}
\contentsline {subsection}{\numberline {6.14.1}Bayes' rule for the urn}{168}
\contentsline {subsection}{\numberline {6.14.2}The probabilities of having a disease}{169}
\contentsline {chapter}{\numberline {7}The devil's in the denominator}{171}
\contentsline {section}{\numberline {7.1}Chapter mission}{171}
\contentsline {section}{\numberline {7.2}Chapter goals}{171}
\contentsline {section}{\numberline {7.3}An introduction to the denominator}{172}
\contentsline {subsection}{\numberline {7.3.1}The denominator as a normalising factor}{172}
\contentsline {subsection}{\numberline {7.3.2}Example: disease}{173}
\contentsline {subsection}{\numberline {7.3.3}Example: the proportion of people who vote for conservatively}{176}
\contentsline {subsection}{\numberline {7.3.4}The denominator as a probability}{178}
\contentsline {subsection}{\numberline {7.3.5}Using the denominator to choose between competing models}{179}
\contentsline {subsection}{\numberline {7.3.6}The denominator for improper priors}{183}
\contentsline {section}{\numberline {7.4}The difficulty with the denominator}{183}
\contentsline {subsection}{\numberline {7.4.1}Multi-parameter discrete model example: the comorbidity between depression and anxiety}{184}
\contentsline {subsection}{\numberline {7.4.2}Continuous multi-parameter example: mean and variance of IQ}{186}
\contentsline {section}{\numberline {7.5}How to dispense with the difficulty: Bayesian computation}{189}
\contentsline {section}{\numberline {7.6}Chapter summary}{191}
\contentsline {section}{\numberline {7.7}Appendix}{191}
\contentsline {part}{III\hspace {1em}Analytic Bayesian methods}{193}
\contentsline {section}{\numberline {7.8}Part mission statement}{195}
\contentsline {section}{\numberline {7.9}Part goals}{195}
\contentsline {chapter}{\numberline {8}An introduction to distributions for the mathematically-un-inclined}{197}
\contentsline {section}{\numberline {8.1}Chapter mission statement}{197}
\contentsline {section}{\numberline {8.2}Chapter goals}{197}
\contentsline {section}{\numberline {8.3}Sampling distributions for likelihoods}{197}
\contentsline {subsubsection}{Bernoulli}{197}
\contentsline {subsubsection}{Binomial}{200}
\contentsline {subsubsection}{Normal}{203}
\contentsline {subsubsection}{Poisson}{203}
\contentsline {subsubsection}{Negative binomial}{203}
\contentsline {subsubsection}{Logistic}{203}
\contentsline {section}{\numberline {8.4}Prior distributions}{203}
\contentsline {subsubsection}{Distributions for probabilities, proportions and percentages}{203}
\contentsline {subsubsection}{Uniform}{203}
\contentsline {subsubsection}{Beta}{203}
\contentsline {subsubsection}{Dirichlet}{203}
\contentsline {section}{\numberline {8.5}Table of distributions, their uses, and reasonable priors}{203}
\contentsline {subsection}{\numberline {8.5.1}Distributions for means and medians}{203}
\contentsline {subsubsection}{Normal}{203}
\contentsline {subsubsection}{Student t}{203}
\contentsline {subsection}{\numberline {8.5.2}Distributions for variances, and shape parameters}{203}
\contentsline {subsubsection}{Gamma}{203}
\contentsline {subsubsection}{Half-Cauchy}{203}
\contentsline {subsubsection}{Inverse Gamma}{203}
\contentsline {subsubsection}{Inverse chi}{203}
\contentsline {subsection}{\numberline {8.5.3}Multinomial - or other regression}{203}
\contentsline {subsection}{\numberline {8.5.4}LBG prior - see Michael Betancourt video and Stan doc}{203}
\contentsline {subsection}{\numberline {8.5.5}Wishart}{204}
\contentsline {subsection}{\numberline {8.5.6}Distributions for categories}{204}
\contentsline {subsubsection}{Categorical}{204}
\contentsline {section}{\numberline {8.6}Chapter summary}{204}
\contentsline {chapter}{\numberline {9}Conjugate priors and their place in Bayesian analysis}{205}
\contentsline {chapter}{\numberline {10}Objective Bayesian analysis}{207}
\contentsline {part}{IV\hspace {1em}A practical guide to doing real life Bayesian analysis: Computational Bayes}{209}
\contentsline {part}{V\hspace {1em}Regression analysis and hierarchical models}{211}
\contentsline {section}{\numberline {10.1}Part mission statement}{213}
\contentsline {section}{\numberline {10.2}Part goals}{213}
\contentsline {chapter}{\numberline {11}Hierarchical models}{215}
\contentsline {chapter}{\numberline {12}Hypothesis testing I: Classical Frequentist vs Bayesian approaches}{217}
\contentsline {chapter}{\numberline {13}Evaluation of model fit}{219}
