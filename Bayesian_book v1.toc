\contentsline {chapter}{\numberline {1}How to best use this book}{9}
\contentsline {part}{I\hspace {1em}Understanding the Bayesian formula}{11}
\contentsline {chapter}{\numberline {2}The subjective worlds of frequentist and Bayesian statistics}{13}
\contentsline {section}{\numberline {2.1}The purpose of statistics}{13}
\contentsline {section}{\numberline {2.2}The world according to classical statistics}{13}
\contentsline {section}{\numberline {2.3}The world according to Bayesian statistics}{13}
\contentsline {section}{\numberline {2.4}Similarities and differences in approaches between classical and Bayesian statistics}{13}
\contentsline {section}{\numberline {2.5}Probability distributions: helping us explicitly state our ignorance}{13}
\contentsline {subsection}{\numberline {2.5.1}What make a probability distribution \textit {valid}? The most important thing today}{14}
\contentsline {subsection}{\numberline {2.5.2}Interpreting discrete and continuous probability distributions}{16}
\contentsline {subsection}{\numberline {2.5.3}Mean and variance of distributions}{17}
\contentsline {subsection}{\numberline {2.5.4}Generalising probability distributions to two dimensions}{21}
\contentsline {subsubsection}{Biased coins: a 2-dimensional discrete probability example}{22}
\contentsline {subsection}{\numberline {2.5.5}Foot length and intelligence: a 2-dimensional continuous probability example}{23}
\contentsline {subsection}{\numberline {2.5.6}Marginal distributions}{24}
\contentsline {subsection}{\numberline {2.5.7}Conditional distributions}{28}
\contentsline {section}{\numberline {2.6}Higher dimensional probability densities: no harder than 2-D, just looks it!}{32}
\contentsline {section}{\numberline {2.7}Independence}{32}
\contentsline {section}{\numberline {2.8}Central Limit Theorems: the most important thing ever}{32}
\contentsline {section}{\numberline {2.9}The Bayesian formula}{32}
\contentsline {subsection}{\numberline {2.9.1}The intuition behind the formula}{33}
\contentsline {section}{\numberline {2.10}The Bayesian inference process from the Bayesian formula}{34}
\contentsline {subsection}{\numberline {2.10.1}Likelihoods}{35}
\contentsline {subsection}{\numberline {2.10.2}Priors}{35}
\contentsline {subsection}{\numberline {2.10.3}The denominator}{36}
\contentsline {subsection}{\numberline {2.10.4}Posteriors: the goal of Bayesian inference}{37}
\contentsline {section}{\numberline {2.11}Implicit vs Explicit subjectivity}{38}
\contentsline {section}{\numberline {2.12}What are the tangible (non-academic) benefits of Bayesian statistics?}{39}
\contentsline {section}{\numberline {2.13}Why don't more people use Bayesian statistics?}{40}
\contentsline {chapter}{\numberline {3}The posterior - the goal of Bayesian inference}{43}
\contentsline {section}{\numberline {3.1}Chapter Mission statement}{43}
\contentsline {section}{\numberline {3.2}Chapter goals}{43}
\contentsline {section}{\numberline {3.3}Expressing uncertainty in a parameter through the posterior probability distribution}{44}
\contentsline {subsection}{\numberline {3.3.1}Do parameters actually exist and have a point value? Bayesian vs classical standpoints}{44}
\contentsline {subsection}{\numberline {3.3.2}Failings of the classical confidence interval}{44}
\contentsline {subsection}{\numberline {3.3.3}The HDI as a better alternative}{45}
\contentsline {subsection}{\numberline {3.3.4}The central posterior interval}{45}
\contentsline {section}{\numberline {3.4}Prediction using a posterior distribution}{45}
\contentsline {subsection}{\numberline {3.4.1}Before experiment, using prior}{45}
\contentsline {subsection}{\numberline {3.4.2}After experiment, using posterior}{45}
\contentsline {section}{\numberline {3.5}Model comparison using the posterior}{45}
\contentsline {section}{\numberline {3.6}Model testing through the posterior}{45}
\contentsline {chapter}{\numberline {4}Likelihoods}{47}
\contentsline {section}{\numberline {4.1}Chapter Mission statement}{47}
\contentsline {section}{\numberline {4.2}Chapter goals}{47}
\contentsline {section}{\numberline {4.3}What is a likelihood?}{48}
\contentsline {section}{\numberline {4.4}Why use 'likelihood' rather than 'probability'?}{50}
\contentsline {section}{\numberline {4.5}What are models and why do we need them?}{53}
\contentsline {section}{\numberline {4.6}How to choose an appropriate likelihood?}{54}
\contentsline {subsection}{\numberline {4.6.1}A likelihood model for an individual's disease status}{55}
\contentsline {subsection}{\numberline {4.6.2}A likelihood model for disease prevalence of a group}{56}
\contentsline {subsection}{\numberline {4.6.3}The intelligence of a group of people}{63}
\contentsline {section}{\numberline {4.7}The subjectivity of model choice}{65}
\contentsline {section}{\numberline {4.8}Maximum likelihood - a short introduction}{66}
\contentsline {subsection}{\numberline {4.8.1}Estimating disease prevalence}{66}
\contentsline {subsection}{\numberline {4.8.2}Estimating the mean and variance in intelligence scores}{69}
\contentsline {section}{\numberline {4.9}Frequentist inference in Maximum Likelihood}{70}
\contentsline {section}{\numberline {4.10}Chapter summary}{72}
\contentsline {chapter}{\numberline {5}Priors}{73}
\contentsline {section}{\numberline {5.1}Chapter Mission statement}{73}
\contentsline {section}{\numberline {5.2}Chapter goals}{73}
\contentsline {section}{\numberline {5.3}What are priors, and what do they represent?}{74}
\contentsline {section}{\numberline {5.4}Why don't we just normalise likelihood by choosing a unity prior?}{76}
\contentsline {section}{\numberline {5.5}The explicit subjectivity of priors}{78}
\contentsline {section}{\numberline {5.6}Combining a prior and likelihood to form a posterior}{78}
\contentsline {subsection}{\numberline {5.6.1}An urn of balls\let \reserved@d =[\def \par }{79}
\contentsline {subsection}{\numberline {5.6.2}Disease proportions revisited}{80}
\contentsline {section}{\numberline {5.7}Constructing priors}{83}
\contentsline {subsection}{\numberline {5.7.1}Vague priors}{85}
\contentsline {subsection}{\numberline {5.7.2}Informative priors}{87}
\contentsline {subsection}{\numberline {5.7.3}The numerator of Bayes' rule determines the shape}{90}
\contentsline {subsection}{\numberline {5.7.4}Eliciting priors}{90}
\contentsline {section}{\numberline {5.8}A strong model is not heavily influenced by priors}{91}
\contentsline {section}{\numberline {5.9}Chapter summary}{94}
\contentsline {section}{\numberline {5.10}Appendix}{94}
\contentsline {subsection}{\numberline {5.10.1}Bayes' rule for the urn}{94}
\contentsline {subsection}{\numberline {5.10.2}The probabilities of having a disease}{95}
\contentsline {chapter}{\numberline {6}The devil's in the denominator}{97}
\contentsline {section}{\numberline {6.1}Chapter mission}{97}
\contentsline {section}{\numberline {6.2}Chapter goals}{97}
\contentsline {section}{\numberline {6.3}An introduction to the denominator}{98}
\contentsline {subsection}{\numberline {6.3.1}The denominator as a normalising factor}{98}
\contentsline {subsection}{\numberline {6.3.2}Example: disease}{99}
\contentsline {subsection}{\numberline {6.3.3}Example: the proportion of people who vote for conservatively}{102}
\contentsline {subsection}{\numberline {6.3.4}The denominator as a probability}{104}
\contentsline {subsection}{\numberline {6.3.5}Using the denominator to choose between competing models}{105}
\contentsline {subsection}{\numberline {6.3.6}The denominator for improper priors}{109}
\contentsline {section}{\numberline {6.4}The difficulty with the denominator}{109}
\contentsline {subsection}{\numberline {6.4.1}Multi-parameter discrete model example: the comorbidity between depression and anxiety}{110}
\contentsline {subsection}{\numberline {6.4.2}Continuous multi-parameter example: mean and variance of IQ}{112}
\contentsline {section}{\numberline {6.5}How to dispense with the difficulty: Bayesian computation}{115}
\contentsline {section}{\numberline {6.6}Chapter summary}{117}
\contentsline {section}{\numberline {6.7}Appendix}{117}
\contentsline {part}{II\hspace {1em}Analytic Bayesian methods}{119}
\contentsline {chapter}{\numberline {7}An introduction to distributions for the mathematically-un-inclined}{121}
\contentsline {chapter}{\numberline {8}Conjugate priors and their place in Bayesian analysis}{123}
\contentsline {chapter}{\numberline {9}Objective Bayesian analysis}{125}
\contentsline {part}{III\hspace {1em}A practical guide to doing real life Bayesian analysis: Computational Bayes}{127}
\contentsline {chapter}{\numberline {10}Hierarchical models}{129}
\contentsline {part}{IV\hspace {1em}Regression analysis and hierarchical models}{131}
\contentsline {chapter}{\numberline {11}Hypothesis testing I: Classical frequentist vs Bayesian approaches}{133}
\contentsline {chapter}{\numberline {12}Evaluation of model fit}{135}
